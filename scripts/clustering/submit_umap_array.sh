#!/bin/bash
#SBATCH --job-name=umap_array
#SBATCH --output=logs/umap_%A_%a.out
#SBATCH --error=logs/umap_%A_%a.err
#SBATCH --array=0-4
#SBATCH --cpus-per-task=8
#SBATCH --mem=64G
#SBATCH --time=4:00:00
#SBATCH --partition=campus-new

# UMAP Array Job for Multiple n_neighbors Values
# Each job in the array computes UMAP with a different n_neighbors

# Configuration
N_NEIGHBORS_VALUES=(15 25 50 100 200)  # Different n_neighbors to test
N_PCS=50                                 # Number of PCA components
MIN_DIST=0.1                            # UMAP min_dist parameter
SUBSAMPLE=1000000                       # Number of genes to subsample (or empty for all)
USE_GPU=""                              # CPU mode (no GPU)

# Paths
PROJECT_DIR="/home/dmullane/SrivatsanLab/Dustin/organism_scale_modelling"
EMBEDDINGS_DIR="${PROJECT_DIR}/data/esm_embeddings"
RESULTS_DIR="${PROJECT_DIR}/results/umap"
PCA_CACHE="${RESULTS_DIR}/pca_cache.npz"
SCRIPT="${PROJECT_DIR}/scripts/embeddings/compute_umap_array.py"

# Create output directories
mkdir -p "${RESULTS_DIR}"
mkdir -p "${PROJECT_DIR}/logs"

# Activate conda environment
source /home/dmullane/micromamba/etc/profile.d/micromamba.sh
micromamba activate esm3_env

# Get n_neighbors value for this array task
N_NEIGHBORS=${N_NEIGHBORS_VALUES[$SLURM_ARRAY_TASK_ID]}

echo "=========================================="
echo "SLURM Job Array Task: ${SLURM_ARRAY_TASK_ID}"
echo "Job ID: ${SLURM_JOB_ID}"
echo "n_neighbors: ${N_NEIGHBORS}"
echo "n_pcs: ${N_PCS}"
echo "Subsample: ${SUBSAMPLE}"
echo "GPU: ${USE_GPU}"
echo "=========================================="

# Output file for this n_neighbors value
OUTPUT_FILE="${RESULTS_DIR}/umap_n${N_NEIGHBORS}_subsample${SUBSAMPLE}.npz"

# Build command
CMD="/home/dmullane/micromamba/envs/esm3_env/bin/python ${SCRIPT}"
CMD="${CMD} --embeddings-dir ${EMBEDDINGS_DIR}"
CMD="${CMD} --output ${OUTPUT_FILE}"
CMD="${CMD} --n-neighbors ${N_NEIGHBORS}"
CMD="${CMD} --n-pcs ${N_PCS}"
CMD="${CMD} --min-dist ${MIN_DIST}"

# Add subsample if specified
if [ ! -z "${SUBSAMPLE}" ]; then
    CMD="${CMD} --subsample ${SUBSAMPLE}"
fi

# Add GPU flag if specified
if [ ! -z "${USE_GPU}" ]; then
    CMD="${CMD} ${USE_GPU}"
fi

# Use cached PCA if it exists (only if using same subsample)
# First job (task 0) creates the cache, others use it
if [ ${SLURM_ARRAY_TASK_ID} -eq 0 ]; then
    # First job: compute and save PCA
    CMD="${CMD} --save-pca ${PCA_CACHE}"
    echo "First job - will compute and save PCA to cache"
else
    # Other jobs: wait for PCA cache to be created, then use it
    echo "Waiting for PCA cache to be created by task 0..."

    # Wait up to 60 minutes for PCA cache
    for i in {1..360}; do
        if [ -f "${PCA_CACHE}" ]; then
            echo "PCA cache found! Using cached PCA."
            CMD="${CMD} --load-cached-pca ${PCA_CACHE}"
            break
        fi

        if [ $i -eq 360 ]; then
            echo "ERROR: PCA cache not found after 60 minutes"
            exit 1
        fi

        sleep 10
    done
fi

echo ""
echo "Command:"
echo "${CMD}"
echo ""

# Run the job
${CMD}

EXIT_CODE=$?

echo ""
echo "=========================================="
echo "Job completed with exit code: ${EXIT_CODE}"
echo "Output: ${OUTPUT_FILE}"
echo "=========================================="

exit ${EXIT_CODE}
